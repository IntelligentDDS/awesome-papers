# MLOps

**Content**


- [MLOps](#mlops)
  - [ML Platform](#ml-platform)
  - [MLOps Incident](#mlops-incident)
  - [ML Anomaly Detection](#ml-anomaly-detection)
  - [ML Fault Tolerance](#ml-fault-tolerance)
  - [ML Communication](#ml-communication)

## ML Platform

- 22_OSDI_Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning [[paper]](https://arxiv.org/pdf/2201.12023.pdf) [[code]](https://github.com/alpa-projects/alpa)
- 18_OSDI_Ray: A Distributed Framework for Emerging AI Applications [[paper]](https://www.usenix.org/system/files/osdi18-moritz.pdf) [[code]](https://github.com/ray-project/ray)

## MLOps Incident

- 23_TSEM_Toward Understanding Deep Learning Framework Bugs [[paper]](https://arxiv.org/pdf/2203.04026.pdf)

## ML Anomaly Detection

23_KDD_AlerTiger: Deep Learning for AI Model Health Monitoring at LinkedIn [[paper]](https://arxiv.org/abs/2306.01977) [[code]](https://github.com/linkedin/AlerTiger/blob/main/alertiger/src/features.py)

## ML Fault Tolerance

- 22_ATC_Sibylla: To Retry or Not To Retry on Deep Learning Job Failure [[paper]](https://www.usenix.org/system/files/atc22-kim-taeyoon.pdf)
- 19_SOSP_Lineage Stash: Fault Tolerance Off the Critical Path [[paper]](https://stephanie-wang.github.io/pdfs/sosp19-lineage-stash.pdf) [[ppt]](https://sosp19.rcs.uwaterloo.ca/slides/wang.pdf)

## ML Communication

- 23_MLSys_On Optimizing the Communication of Model Parallelism [[paper]](https://arxiv.org/pdf/2211.05322.pdf)